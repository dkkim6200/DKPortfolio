<a href="https://github.com/dkkim6200/azure-kinect-ar">HoloKinect on Github</a>

<p>I used Unity and WebRTC to achieve a real-time streaming of pointclouds from Azure Kinect to HoloLens 2. The app gives a teleportation-like experience to the users, where the user can be transported from anywhere in the world to where the Kinect is.</p>

<p>Much of the fast rendering was achieved thanks to the use of RGB-Depth video (shown in second slide) and HLSL Shader. RGB-D video allowed the streaming of depth information over the network greatly faster than simply streaming the depth float-array. The shader helped achieve an efficient converting RGB-D image to point-clouds that created a great overhead for the CPU.</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/7q7NjP-q10g" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
